# app/services/topgainers_service.py
import asyncio
import json
import logging
from typing import List, Optional, Dict, Any, Tuple
from datetime import datetime, timedelta
import pytz

from app.database import get_db
from app.config import settings
from app.models.topgainers_model import TopGainers
from app.schemas.websocket_schema import TopGainerData, db_to_topgainer_data

logger = logging.getLogger(__name__)

class MarketTimeChecker:
    """ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ ì‹œê°„ ì²´í¬ í´ë˜ìŠ¤ (ê°„ì†Œí™”)"""
    
    def __init__(self):
        self.us_eastern = pytz.timezone('US/Eastern')
        # ì£¼ìš” ê³µíœ´ì¼ë§Œ í¬í•¨ (ê°„ì†Œí™”)
        self.market_holidays = {
            '2024-12-25', '2025-01-01', '2025-01-20', '2025-07-04', '2025-12-25'
        }
    
    def is_market_open(self) -> bool:
        """í˜„ì¬ ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ì´ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸"""
        try:
            now_utc = datetime.utcnow().replace(tzinfo=pytz.UTC)
            now_et = now_utc.astimezone(self.us_eastern)
            
            # ì£¼ë§ ì²´í¬
            if now_et.weekday() >= 5:
                return False
            
            # ê³µíœ´ì¼ ì²´í¬
            if now_et.strftime('%Y-%m-%d') in self.market_holidays:
                return False
            
            # ì •ê·œ ê±°ë˜ì‹œê°„: 9:30 AM - 4:00 PM ET
            market_open = now_et.replace(hour=9, minute=30, second=0, microsecond=0)
            market_close = now_et.replace(hour=16, minute=0, second=0, microsecond=0)
            
            return market_open <= now_et <= market_close
            
        except Exception as e:
            logger.error(f"âŒ ì‹œì¥ ì‹œê°„ í™•ì¸ ì˜¤ë¥˜: {e}")
            return False

class TopGainersService:
    """
    ğŸ¯ TopGainers ì „ìš© ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    
    top_gainers í…Œì´ë¸” ì¤‘ì‹¬ì˜ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    ì¥ì¤‘ì—ëŠ” Redis, ì¥ë§ˆê° ì‹œì—ëŠ” PostgreSQLì—ì„œ ìµœì‹  ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """TopGainersService ì´ˆê¸°í™”"""
        self.redis_client = None
        self.market_checker = MarketTimeChecker()
        
        # ìºì‹œ
        self.symbol_category_cache: Dict[str, str] = {}
        self.last_cache_update = 0
        self.cache_ttl = 300  # 5ë¶„
        
        # í†µê³„
        self.stats = {
            "api_calls": 0,
            "redis_calls": 0,
            "db_calls": 0,
            "cache_hits": 0,
            "market_closed_calls": 0,
            "errors": 0,
            "last_update": None
        }
        
        logger.info("âœ… TopGainersService ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def init_redis(self) -> bool:
        """Redis ì—°ê²° ì´ˆê¸°í™”"""
        try:
            import redis.asyncio as redis
            
            self.redis_client = redis.Redis(
                host=settings.REDIS_HOST,
                port=settings.REDIS_PORT,
                db=settings.REDIS_DB,
                password=settings.REDIS_PASSWORD,
                decode_responses=True,
                socket_connect_timeout=5,
                socket_timeout=5
            )
            
            await self.redis_client.ping()
            logger.info("âœ… TopGainers Redis ì—°ê²° ì„±ê³µ")
            return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ TopGainers Redis ì—°ê²° ì‹¤íŒ¨: {e}")
            self.redis_client = None
            return False
    
    # =========================
    # ğŸ¯ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
    # =========================
    
    def get_latest_batch_symbols_with_categories(self) -> Dict[str, List[str]]:
        """
        ìµœì‹  ë°°ì¹˜ì˜ 50ê°œ ì‹¬ë³¼ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë°˜í™˜
        
        Returns:
            Dict[str, List[str]]: ì¹´í…Œê³ ë¦¬ë³„ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
            {
                "top_gainers": ["GXAI", "PRFX", ...],
                "top_losers": ["BNAIW", "VELO", ...], 
                "most_actively_traded": ["ADD", "OPEN", ...]
            }
        """
        try:
            db = next(get_db())
            
            # ìµœì‹  batch_id ì¡°íšŒ
            latest_batch = TopGainers.get_latest_batch_id(db)
            if not latest_batch:
                logger.warning("ğŸ“Š top_gainers í…Œì´ë¸”ì— ë°ì´í„° ì—†ìŒ")
                return {}
            
            batch_id = latest_batch[0]
            
            # ë°°ì¹˜ì˜ ëª¨ë“  ë°ì´í„° ì¡°íšŒ
            db_objects = db.query(TopGainers).filter(
                TopGainers.batch_id == batch_id
            ).order_by(TopGainers.category, TopGainers.rank_position).all()
            
            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜
            result = {}
            for obj in db_objects:
                category = obj.category
                if category not in result:
                    result[category] = []
                result[category].append(obj.symbol)
            
            # ìºì‹œ ì—…ë°ì´íŠ¸
            self.symbol_category_cache.clear()
            for obj in db_objects:
                self.symbol_category_cache[obj.symbol] = obj.category
            self.last_cache_update = datetime.utcnow().timestamp()
            
            logger.debug(f"ğŸ“Š ìµœì‹  ë°°ì¹˜ ì‹¬ë³¼ ì¡°íšŒ: {sum(len(symbols) for symbols in result.values())}ê°œ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ìµœì‹  ë°°ì¹˜ ì‹¬ë³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            self.stats["errors"] += 1
            return {}
        finally:
            db.close()
    
    async def get_market_data_with_categories(self, category: str = None, limit: int = 50) -> List[TopGainerData]:
        """
        ğŸ¯ ì‹œì¥ ìƒíƒœì— ë”°ë¥¸ ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ì¡°íšŒ
        
        Args:
            category: ì¹´í…Œê³ ë¦¬ í•„í„° (None=ì „ì²´, "top_gainers", "top_losers", "most_actively_traded")
            limit: ë°˜í™˜í•  ìµœëŒ€ ê°œìˆ˜
            
        Returns:
            List[TopGainerData]: ì¹´í…Œê³ ë¦¬ ì •ë³´ê°€ í¬í•¨ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        self.stats["api_calls"] += 1
        
        try:
            is_market_open = self.market_checker.is_market_open()
            
            if is_market_open and self.redis_client:
                # ğŸ”„ ì¥ì¤‘: Redisì—ì„œ ì‹¤ì‹œê°„ ë°ì´í„°
                data = await self._get_data_from_redis(category, limit)
                logger.debug(f"ğŸ“Š Redisì—ì„œ TopGainers ë°ì´í„° ì¡°íšŒ: {len(data)}ê°œ")
            else:
                # ğŸ’¾ ì¥ë§ˆê°: PostgreSQLì—ì„œ ìµœì‹  ë°ì´í„°
                data = await self._get_data_from_db(category, limit)
                logger.debug(f"ğŸ“Š PostgreSQLì—ì„œ TopGainers ë°ì´í„° ì¡°íšŒ: {len(data)}ê°œ")
                self.stats["market_closed_calls"] += 1
            
            self.stats["last_update"] = datetime.utcnow()
            return data
            
        except Exception as e:
            logger.error(f"âŒ TopGainers ì‹œì¥ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            self.stats["errors"] += 1
            return []
    
    async def _get_data_from_redis(self, category: str = None, limit: int = 50) -> List[TopGainerData]:
        """Redisì—ì„œ TopGainers ë°ì´í„° ì¡°íšŒ"""
        try:
            self.stats["redis_calls"] += 1
            
            # ìµœì‹  ë°°ì¹˜ ì‹¬ë³¼ë“¤ ê°€ì ¸ì˜¤ê¸° (ì¹´í…Œê³ ë¦¬ ë§¤í•‘ í¬í•¨)
            symbol_categories = self.get_latest_batch_symbols_with_categories()
            
            # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
            target_symbols = []
            if category:
                target_symbols = symbol_categories.get(category, [])
            else:
                # ì „ì²´ ì‹¬ë³¼
                for symbols in symbol_categories.values():
                    target_symbols.extend(symbols)
            
            if not target_symbols:
                logger.warning(f"ğŸ“Š Redis: {category} ì¹´í…Œê³ ë¦¬ì— ì‹¬ë³¼ ì—†ìŒ")
                return []
            
            # Redisì—ì„œ ë³‘ë ¬ ì¡°íšŒ
            pipeline = self.redis_client.pipeline()
            redis_keys = [f"latest:stocks:topgainers:{symbol}" for symbol in target_symbols]
            
            for key in redis_keys:
                pipeline.get(key)
            
            results = await pipeline.execute()
            
            # JSON íŒŒì‹± ë° TopGainerData ë³€í™˜
            data = []
            for i, result in enumerate(results):
                if result:
                    try:
                        json_data = json.loads(result)
                        symbol = target_symbols[i]
                        
                        # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ê°€ (ìºì‹œì—ì„œ)
                        redis_category = json_data.get('category', 'unknown')
                        cached_category = self.symbol_category_cache.get(symbol, redis_category)
                        
                        # TopGainerData ìƒì„±
                        topgainer_data = TopGainerData(
                            batch_id=0,  # Redisì—ì„œëŠ” batch_id ì—†ìŒ
                            symbol=symbol,
                            category=cached_category,
                            last_updated=datetime.utcnow().isoformat(),
                            price=json_data.get('price'),
                            volume=json_data.get('volume'),
                            change_amount=json_data.get('change_amount'),
                            change_percentage=json_data.get('change_percentage'),
                            rank_position=None,  # Redisì—ëŠ” ìˆœìœ„ ì •ë³´ ì—†ìŒ
                            created_at=datetime.utcnow().isoformat()
                        )
                        data.append(topgainer_data)
                        
                    except (json.JSONDecodeError, ValueError) as e:
                        logger.warning(f"âš ï¸ Redis ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨ ({target_symbols[i]}): {e}")
                        continue
            
            # ê°€ê²© ê¸°ì¤€ ì •ë ¬ ë° ì œí•œ
            data.sort(key=lambda x: x.price or 0, reverse=True)
            return data[:limit]
            
        except Exception as e:
            logger.error(f"âŒ Redis TopGainers ì¡°íšŒ ì‹¤íŒ¨: {e}")
            # Redis ì‹¤íŒ¨ ì‹œ DB fallback
            return await self._get_data_from_db(category, limit)
    
    async def _get_data_from_db(self, category: str = None, limit: int = 50) -> List[TopGainerData]:
        """PostgreSQLì—ì„œ TopGainers ë°ì´í„° ì¡°íšŒ"""
        try:
            self.stats["db_calls"] += 1
            
            db = next(get_db())
            
            # ìµœì‹  batch_id ì¡°íšŒ
            latest_batch = TopGainers.get_latest_batch_id(db)
            if not latest_batch:
                logger.warning("ğŸ“Š DB: top_gainers í…Œì´ë¸”ì— ë°ì´í„° ì—†ìŒ")
                return []
            
            batch_id = latest_batch[0]
            
            # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
            if category:
                db_objects = TopGainers.get_by_category(db, category, batch_id, limit)
            else:
                db_objects = db.query(TopGainers).filter(
                    TopGainers.batch_id == batch_id
                ).order_by(TopGainers.rank_position.asc().nulls_last()).limit(limit).all()
            
            # Pydantic ëª¨ë¸ë¡œ ë³€í™˜
            data = [db_to_topgainer_data(obj) for obj in db_objects]
            return data
            
        except Exception as e:
            logger.error(f"âŒ DB TopGainers ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
        finally:
            db.close()
    
    def get_category_statistics(self) -> Dict[str, Any]:
        """
        ğŸ¯ ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ì •ë³´ ì¡°íšŒ
        
        Returns:
            Dict[str, Any]: ì¹´í…Œê³ ë¦¬ í†µê³„
            {
                "categories": {
                    "top_gainers": 20,
                    "top_losers": 10,
                    "most_actively_traded": 20
                },
                "total": 50,
                "last_updated": "2025-08-21T10:30:00Z",
                "market_status": "OPEN"
            }
        """
        try:
            db = next(get_db())
            
            # ìµœì‹  batch_id ì¡°íšŒ
            latest_batch = TopGainers.get_latest_batch_id(db)
            if not latest_batch:
                return {
                    "categories": {},
                    "total": 0,
                    "last_updated": None,
                    "market_status": "UNKNOWN"
                }
            
            batch_id = latest_batch[0]
            
            # ì¹´í…Œê³ ë¦¬ë³„ ê°œìˆ˜ ì¡°íšŒ
            from sqlalchemy import func
            category_counts = {}
            
            categories = db.query(
                TopGainers.category,
                func.count(TopGainers.symbol)
            ).filter(
                TopGainers.batch_id == batch_id
            ).group_by(TopGainers.category).all()
            
            total = 0
            for category, count in categories:
                if category:
                    category_counts[category] = count
                    total += count
            
            # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„
            last_updated_obj = db.query(TopGainers).filter(
                TopGainers.batch_id == batch_id
            ).order_by(TopGainers.last_updated.desc()).first()
            
            last_updated = None
            if last_updated_obj:
                last_updated = last_updated_obj.last_updated.isoformat()
            
            # ì‹œì¥ ìƒíƒœ
            market_status = "OPEN" if self.market_checker.is_market_open() else "CLOSED"
            
            return {
                "categories": category_counts,
                "total": total,
                "batch_id": batch_id,
                "last_updated": last_updated,
                "market_status": market_status,
                "data_source": "redis" if market_status == "OPEN" and self.redis_client else "database"
            }
            
        except Exception as e:
            logger.error(f"âŒ TopGainers í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            self.stats["errors"] += 1
            return {"categories": {}, "total": 0, "error": str(e)}
        finally:
            db.close()
    # =========================
# 5. TopGainers ì„œë¹„ìŠ¤ í™•ì¥
# =========================

# app/services/topgainers_service.py (ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€)

    async def get_realtime_polling_data(self, limit: int, category: Optional[str] = None):
        """
        TopGainers ì‹¤ì‹œê°„ í´ë§ ë°ì´í„° ("ë”ë³´ê¸°" ë°©ì‹)
        
        Args:
            limit: ë°˜í™˜í•  í•­ëª© ìˆ˜ (1ë²ˆë¶€í„° limitë²ˆê¹Œì§€)
            category: ì¹´í…Œê³ ë¦¬ í•„í„° (Noneì´ë©´ ì „ì²´)
        
        Returns:
            dict: í´ë§ ì‘ë‹µ ë°ì´í„°
        """
        try:
            # ğŸ¯ WebSocketê³¼ ë™ì¼í•œ ë°ì´í„° ì†ŒìŠ¤ ì‚¬ìš©
            if category:
                # íŠ¹ì • ì¹´í…Œê³ ë¦¬ë§Œ ì¡°íšŒ
                all_data = await self.get_category_data_for_websocket(category, limit=200)
            else:
                # ì „ì²´ ì¹´í…Œê³ ë¦¬ ì¡°íšŒ
                all_data = await self.get_market_data_with_categories(limit=200)
            
            if not all_data:
                logger.warning("ğŸ“Š TopGainers ì‹¤ì‹œê°„ ë°ì´í„° ì—†ìŒ")
                return {
                    "data": [],
                    "metadata": {
                        "current_count": 0,
                        "total_available": 0,
                        "has_more": False,
                        "next_limit": limit,
                        "timestamp": datetime.utcnow().isoformat(),
                        "data_source": "no_data",
                        "message": "ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                    }
                }
            
            # ìˆœìœ„ë³„ ì •ë ¬ (rank_position ê¸°ì¤€)
            all_data.sort(key=lambda x: x.rank_position or 999)
            
            # ìˆœìœ„ ì¬ë¶€ì—¬ (1ë¶€í„° ì‹œì‘)
            for i, item in enumerate(all_data):
                item.rank_position = i + 1
            
            # limitë§Œí¼ ìë¥´ê¸°
            limited_data = all_data[:limit]
            total_available = len(all_data)
            
            # ì¹´í…Œê³ ë¦¬ í†µê³„ ê³„ì‚°
            category_stats = {}
            if not category:
                # ì „ì²´ ì¡°íšŒì¸ ê²½ìš° ì¹´í…Œê³ ë¦¬ë³„ ê°œìˆ˜ ì œê³µ
                for item in all_data:
                    cat = item.category or "unknown"
                    category_stats[cat] = category_stats.get(cat, 0) + 1
            
            return {
                "data": [item.model_dump() for item in limited_data],
                "metadata": {
                    "current_count": len(limited_data),
                    "total_available": total_available,
                    "has_more": limit < total_available,
                    "next_limit": min(limit + 50, total_available),
                    "timestamp": datetime.utcnow().isoformat(),
                    "data_source": "redis_realtime",
                    "category_filter": category,
                    "category_stats": category_stats if category_stats else None,
                    "market_status": self._get_market_status()
                }
            }
        
        except Exception as e:
            logger.error(f"âŒ TopGainers ì‹¤ì‹œê°„ í´ë§ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    def _get_market_status(self):
        """ì‹œì¥ ìƒíƒœ ì¡°íšŒ (TopGainersìš©)"""
        try:
            from app.services.websocket_service import MarketTimeChecker
            market_checker = MarketTimeChecker()
            status = market_checker.get_market_status()
            return {
                "is_open": status["is_open"],
                "status": status["status"]
            }
        except Exception as e:
            return {"is_open": False, "status": "UNKNOWN"}
    
    async def get_symbol_data(self, symbol: str, category: str = None) -> Optional[TopGainerData]:
        """
        íŠ¹ì • ì‹¬ë³¼ì˜ TopGainers ë°ì´í„° ì¡°íšŒ
        
        Args:
            symbol: ì£¼ì‹ ì‹¬ë³¼
            category: ì¹´í…Œê³ ë¦¬ í•„í„° (ì„ íƒì‚¬í•­)
            
        Returns:
            Optional[TopGainerData]: ì‹¬ë³¼ ë°ì´í„° (ì—†ìœ¼ë©´ None)
        """
        try:
            symbol = symbol.upper().strip()
            is_market_open = self.market_checker.is_market_open()
            
            if is_market_open and self.redis_client:
                # Redisì—ì„œ ì¡°íšŒ
                redis_key = f"latest:stocks:topgainers:{symbol}"
                result = await self.redis_client.get(redis_key)
                
                if result:
                    json_data = json.loads(result)
                    redis_category = json_data.get('category', 'unknown')
                    
                    # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                    if category and redis_category != category:
                        return None
                    
                    return TopGainerData(
                        batch_id=0,
                        symbol=symbol,
                        category=redis_category,
                        last_updated=datetime.utcnow().isoformat(),
                        price=json_data.get('price'),
                        volume=json_data.get('volume'),
                        change_amount=json_data.get('change_amount'),
                        change_percentage=json_data.get('change_percentage'),
                        rank_position=None,
                        created_at=datetime.utcnow().isoformat()
                    )
            
            # DBì—ì„œ ì¡°íšŒ (Redis ì‹¤íŒ¨ ë˜ëŠ” ì¥ ë§ˆê°)
            db = next(get_db())
            db_object = TopGainers.get_symbol_data(db, symbol, category)
            
            if db_object:
                return db_to_topgainer_data(db_object)
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ ì‹¬ë³¼ {symbol} ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
        finally:
            if 'db' in locals():
                db.close()
    
    # =========================
    # ğŸ¯ WebSocket ì§€ì› ë©”ì„œë“œ
    # =========================
    
    async def get_realtime_updates(self, last_update_time: datetime = None) -> List[TopGainerData]:
        """
        ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ìš© ë°ì´í„° ì¡°íšŒ (WebSocketì—ì„œ ì‚¬ìš©)
        
        Args:
            last_update_time: ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ (ë³€ê²½ ê°ì§€ìš©)
            
        Returns:
            List[TopGainerData]: ë³€ê²½ëœ ë°ì´í„°ë§Œ ë°˜í™˜
        """
        try:
            # ì „ì²´ ë°ì´í„° ì¡°íšŒ
            all_data = await self.get_market_data_with_categories()
            
            # ë³€ê²½ ê°ì§€ ë¡œì§ (ê°„ë‹¨íˆ ì „ì²´ ë°˜í™˜ - ìƒì„¸í•œ diffëŠ” WebSocket ë§¤ë‹ˆì €ì—ì„œ)
            return all_data
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    async def get_category_data_for_websocket(self, category: str, limit: int = 20) -> List[TopGainerData]:
        """
        WebSocketìš© ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ì¡°íšŒ
        
        Args:
            category: ì¹´í…Œê³ ë¦¬ (top_gainers, top_losers, most_actively_traded)
            limit: ë°˜í™˜í•  ìµœëŒ€ ê°œìˆ˜
            
        Returns:
            List[TopGainerData]: ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„°
        """
        return await self.get_market_data_with_categories(category, limit)
    
    # =========================
    # í†µê³„ ë° í—¬ìŠ¤ì²´í¬
    # =========================
    
    def get_service_stats(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ í†µê³„ ì •ë³´ ë°˜í™˜"""
        return {
            "performance": {
                "api_calls": self.stats["api_calls"],
                "redis_calls": self.stats["redis_calls"],
                "db_calls": self.stats["db_calls"],
                "cache_hits": self.stats["cache_hits"],
                "market_closed_calls": self.stats["market_closed_calls"],
                "errors": self.stats["errors"]
            },
            "data_status": {
                "last_update": self.stats["last_update"].isoformat() if self.stats["last_update"] else None,
                "cached_symbols": len(self.symbol_category_cache),
                "cache_age_seconds": datetime.utcnow().timestamp() - self.last_cache_update
            },
            "health": {
                "redis_available": self.redis_client is not None,
                "market_status": "OPEN" if self.market_checker.is_market_open() else "CLOSED",
                "error_rate": self.stats["errors"] / max(self.stats["api_calls"], 1) * 100
            }
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬"""
        health_info = {
            "timestamp": datetime.utcnow().isoformat(),
            "status": "healthy",
            "services": {}
        }
        
        # Redis ìƒíƒœ í™•ì¸
        if self.redis_client:
            try:
                await asyncio.wait_for(self.redis_client.ping(), timeout=3.0)
                health_info["services"]["redis"] = {"status": "connected"}
            except Exception as e:
                health_info["services"]["redis"] = {"status": "disconnected", "error": str(e)}
                health_info["status"] = "degraded"
        else:
            health_info["services"]["redis"] = {"status": "not_configured"}
            health_info["status"] = "degraded"
        
        # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
        try:
            db = next(get_db())
            latest_batch = TopGainers.get_latest_batch_id(db)
            
            if latest_batch:
                health_info["services"]["database"] = {"status": "connected", "latest_batch": latest_batch[0]}
            else:
                health_info["services"]["database"] = {"status": "connected", "data": "empty"}
                health_info["status"] = "degraded"
            
            db.close()
        except Exception as e:
            health_info["services"]["database"] = {"status": "disconnected", "error": str(e)}
            health_info["status"] = "unhealthy"
        
        return health_info
    
    async def shutdown(self):
        """ì„œë¹„ìŠ¤ ì¢…ë£Œ ì²˜ë¦¬"""
        try:
            if self.redis_client:
                await self.redis_client.close()
                logger.info("âœ… TopGainers Redis ì—°ê²° ì¢…ë£Œ")
            
            self.symbol_category_cache.clear()
            logger.info("âœ… TopGainersService ì¢…ë£Œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ TopGainersService ì¢…ë£Œ ì‹¤íŒ¨: {e}")